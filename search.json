[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my website",
    "section": "",
    "text": "My name is Julian and I study at UTD and I will use this website to upload course content. I am studying in the double-degree program International Political Economy at the University of Texas at Dallas, and at the Philipps-University Marburg (Germany)\nHere you can find a short CV of myself:\n\nMy Assignments:\nAssignment 1: Qualtrics Introduction\n2. How is the survey structured?\nThe survey starts with an introduction and appreciation of participation, which is probably part of the survey to incentivize the participants to complete the survey. After the introduction the survey continues with a question about the opinion on different topics related to movies and concerns like violence and sexual content in movies.\nAfter that question the survey seems to be structured without a reasonable concept. The questions about demographics are placed at the end of the survey, which is not common in surveys. The other questions aim at the willingness to pay for software and hardware (DVDs) and several different topics and are distributed in a random way. For example, some questions about if the participants has a DVD recorder, come after the question if the participant would like to have software that can control content of violence etc..\n2.1 What is the questionnaire composed of?\nThe first question asks about the opinion of the participant on a scale from strongly disagree to strongly agree, so that there is a scale of five options.\nOther questions ask for a yes or no, which can also be interpreted as agreement or disagreement.\nSome other questions show different ranges as answer. Those questions are used to find insights about the willingness to pay (e.g., Question 5).\nLike already mentioned in the previous questions, there are a couple of demographic questions in the end of the survey.\nOther questions just ask for nominal values, like what kind of DVD player the participant possesses.\nMore technically, there are Drop-down menus, tables, multiple choice questions and single choice questions.\n2.2 How are the questions ordered?\nThe questions are ordered in a more or less random way, so what the survey is not doing is from going from the general topics to the specific topics.\n7. What can be done to improve respondents’ experience?\nFirst of all, the survey could be more mobile friendly, since many people use the phone for participating and there are technical possibilities to do so! Also, the structure of the survey could be improved by asking general questions first and then proceeding to the more complex questions, where the context of the other questions is available. Another topic that needs to be addressed is that some questions are formulated in a confusing way. For example, Question 3 and 11 have some kind of overlap and could be reformulated in a clearer and better way.\nhttps://utdallas.qualtrics.com/jfe/form/SV_71lvbXqq7u9ccVo\nFurther Assignments:\n4. What is the difference between this block and the previous instrument?\nAdding a further block with questions about income and education implies that these questions were not designed for the specific survey of Diversity and Inclusiveness. For that reason, the questions should be adapted to the survey or our own questions should be formulated. Also, adding questions from other surveys can be formulated in another context, e.g., the income and education questions come from a survey for the US, but it could also be the case that it comes from a country in Africa, where the income scale should be adapted to the country where the actual survey will be conducted.\nhttps://utdallas.qualtrics.com/jfe/form/SV_beZJSTLyv5xCxEi\nAssignment 2: Google Trends\nA: Panel\nI created a contact list with some email adresses, that will recieve the survey at the 30th September at 12pm. Also I included a question at the end of the survey that asks for an email adress, so that I can collect other email adresses.\n\nhttps://utdallas.qualtrics.com/jfe/form/SV_71lvbXqq7u9ccVo\n1. Analyse the data\nI searched google trends on the terms Trump, Biden and Election. In the first result one can see the interest over time of those search terms. A value of 100 means the highest popularity, which also implies that a value of 50 means that the term was half as popular compared to the value 100. Therefore, google trends compares the popularity of the search term, which is a relative measure, as it searches for the most popular term at a specific time and sets it as a benchmark. I looked into the interest over time for the last 30 days. One can see that the term Trump was most popular on the 25th of August. The other search terms were very unpopular compared to that value since the highest score for Biden is 10 on the 14th of September. The term election also was very unpopular compared to Trump, with a value of 3 on a couple of days.\nAfter that I looked at the data for “Compared breakdown by subregion”. In that category, you can see how big the shares of the terms were relative to all observations of those terms. I looked into those patterns on the state level and in every State, Trump was the most popular term out of the chosen.\n2. What are the differences between the two methods?\nIf you download the data on google trends, you will get them in a csv format, which you can use in every processing software basically. Also, if you want to analyze all categories together, you need to download the data separately and then add them together manually. If you use R to analyze the data, you have the data all together and can use it more easily. Also, you have more possibilities to compare the data with different keywords and are able to perform sophisticated analysis.\nIn the plot we can see the hits of the keywords transgender, feminism and woman rights. With R it is more easy to organize the data, because R provides to opportunity to perform many analysis. For example you can also use GIS methods and connect that with google trends data or social media data.\n\nAssignment 3: Text Analysis\nAnalyzing summit data of Joe Biden and Xi Xingping with quanteda package.\nAnalyzing summit data of Joe Biden and Xi Xingping with quanteda package.\nFirst, we perform a Latent Semantic Analysis which analyzes the relationship between a set of documents, in this case tweets about the summit. We filter out the most connected hashtags of the data and find that the top tags in this analysis are: #china #biden #xijinping #joebiden #america #americans #coronavirus #fentanyl #xi #uyghurgenocide\nAfter that we analyze the co-occurrence of the different tags. In the following figure we can see these relationships of the top tags. When there are hash-tags about human rights they are often connected to the uyguhrs and also to the tibetians, while when there are hash-tags about Joe Biden, these hashtags are often connected to the hash-tags of fentanyl and coronavirus. Using this method can help in seeing how people connect topics with each other.\n\nNext, we perform the same analysis with the @ and therefore the linked accounts or posting accounts in relation to the summit.\n\nAfterwards we performed an analysis about US speeches.\n\n\nIn those plots we can see the usage of the specific keywords for the different speeches of the presidents after 1949. Comparing the last three presidents, one can see that Obama and Biden use the word people more often in their speeches than Trump, which can also be a hint about the focus of the different campaigns of those presidents.\nWhat is Wordfish?\nWordfish is a scaling model of one-dimensional document positions. Meaning that it is able to locate different documents on different positions, like party positions. With this tool it is possible to compare the change of a position in time-series data. For example it is possible to examine the change of party positions over time and compare changes in the political spectrum.\nAssignment 5:\nIn this Assignment we were asked to analyze Youtube Data via an API of an google developer account. Unfortunately, an error occurred, so that I was not able to fulfill the task.\nAssignment 6\nThe text by Martin Luther King is approached by the easypackages package in R. With the function htmlTreeParse and unlist R reads out all the paragraphs and parse them. After that we vectorize the text, meaning the we convert the text into numerical representation. After that we edit the data a little bit more, removing the punctuations etc. Finally we create a wordcloud for the document, representing the keywords of the text. You can see the wordcloud below:\n In the second part of the assignment we analyze a wikipedia article, using the package tidyverse and rvest. First we read out the wikipedia page into R.\nAssignment 7:\nIn Assignment 7 I downloaded all Documents of congressional hearings from the 118th Congress in the Department of Foreign Affairs from the website https://www.govinfo.gov/app/search/ . First I downloaded a csv file from the website with all the 12 relevant pdfs. With the help of this document I was able to download those documents in an automated way in the chosen directory on my Laptop.\nAssignment 8:\nIn Assignment 8 I first created an API with the website http://api.census.gov/data/key_signup.html, which worked after a couple of minutes. With this API I was able to download census data for 2019 with its geographical location. With these information I created a map of the median age of the different US States, which you can find below.\n\nIn the second part of the Assignment I created maps for the Income level of Texas and later for Dallas. Those pictures can be seen below.\n\n\n\n\n1+1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  }
]